import streamlit as st
import pandas as pd
import subprocess
import os
import json
import plotly.express as px

st.set_page_config(
    page_title="Marina-Socioling",
    layout="wide",
    initial_sidebar_state="collapsed",
)

DADOS_PATH = os.environ.get("DADOS_PATH", "/app/dados")
RBRUL_SCRIPT = "/app/scripts/run_rbrul.R"

# MÃ©tricas reais da versÃ£o instalada
METRICAS_PMI        = ["pmi", "n_pmi", "p_pmi", "np_pmi", "w_pmi", "nw_pmi", "pw_pmi", "npw_pmi",
                        "np_relevance", "nw_relevance", "npw_relevance"]
METRICAS_LEXICAIS   = ["ttr", "root_ttr", "maas", "log_ttr"]
METRICAS_CORPUS     = ["freq", "stats"]
TODAS_METRICAS      = METRICAS_PMI + METRICAS_LEXICAIS + METRICAS_CORPUS

CANDIDATOS_SOCIAIS  = ["genero", "gÃªnero", "faixa_etaria", "faixa etÃ¡ria", "escolaridade",
                       "regiao", "regiÃ£o", "estilo", "classe", "sexo", "grupo"]
CANDIDATOS_FALANTE  = ["falante", "speaker", "informante", "participante", "sujeito"]

# â”€â”€ Helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def detectar_binÃ¡rias(df):
    return [c for c in df.columns if df[c].nunique() == 2]

def detectar_textos(df):
    """Colunas onde a mÃ©dia de palavras por cÃ©lula Ã© > 3."""
    cols = []
    for col in df.columns:
        if df[col].dtype == object:
            media = df[col].dropna().str.split().str.len().mean()
            if media and media > 3:
                cols.append(col)
    return cols

def detectar_falante(df):
    for col in df.columns:
        if col.lower() in CANDIDATOS_FALANTE:
            return col
    return None

def detectar_sociais(df, excluir):
    """Retorna todas as colunas que parecem variÃ¡veis sociais."""
    sociais = []
    for col in df.columns:
        if col in excluir:
            continue
        if col.lower() in CANDIDATOS_SOCIAIS:
            sociais.append(col)
    if not sociais:
        # fallback: colunas categÃ³ricas com poucos valores Ãºnicos
        for col in df.columns:
            if col not in excluir and df[col].dtype == object and 2 <= df[col].nunique() <= 10:
                sociais.append(col)
    return sociais

def corrigir_texto(df, col):
    """Garante espaÃ§o entre tokens grudados."""
    import re
    df[col] = df[col].astype(str).apply(lambda x: re.sub(r'([a-zÃ¡Ã Ã£Ã¢Ã©ÃªÃ­Ã³Ã´ÃµÃºÃ¼Ã§A-Z])([A-ZÃÃ€ÃƒÃ‚Ã‰ÃŠÃÃ“Ã”Ã•ÃšÃœÃ‡])', r'\1 \2', x))
    return df

def detectar_idioma(df, cols_texto):
    amostra = ""
    for col in cols_texto:
        amostra += " " + " ".join(df[col].dropna().head(50).tolist()).lower()

    palavras_amostra = set(amostra.split())

    # â”€â”€ DetecÃ§Ã£o por script (caracteres Ãºnicos) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # CirÃ­lico â†’ russo imediato
    chars_cirÃ­lico = sum(1 for c in amostra if '\u0400' <= c <= '\u04FF')
    if chars_cirÃ­lico > 10:
        return "ru"

    # Umlauts e ÃŸ â†’ forte indicador de alemÃ£o
    chars_de = sum(1 for c in amostra if c in "Ã¤Ã¶Ã¼ÃŸÃ„Ã–Ãœ")
    if chars_de > 5:
        return "de"

    # â”€â”€ Stopwords por idioma â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    stopwords = {
        "pt": [
            "que", "nÃ£o", "uma", "com", "para", "mais", "por", "ele", "ela", "mas",
            "como", "seu", "sua", "dos", "das", "nos", "nas", "isso", "esse", "essa",
            "este", "esta", "aqui", "entÃ£o", "tambÃ©m", "jÃ¡", "muito", "bem", "quando",
            "onde", "quem", "qual", "porque", "assim", "ainda", "depois", "antes",
            "sempre", "nunca", "havia", "seria", "estava", "foram", "tinha", "tudo",
            "nada", "cada", "outro", "outra", "gente", "hoje", "agora", "aquele",
            "aquela", "nosso", "nossa", "vocÃªs", "eles", "elas", "numa", "nesse",
            "nessa", "desse", "dessa", "Ã quele", "Ã quela", "sobre", "entre", "atÃ©"
        ],
        "en": [
            "the", "and", "is", "of", "to", "in", "that", "it", "was", "for",
            "on", "are", "with", "his", "they", "at", "be", "this", "from", "or",
            "had", "by", "not", "but", "what", "all", "were", "when", "we", "there",
            "can", "an", "your", "which", "their", "said", "if", "do", "into", "has",
            "more", "her", "him", "see", "time", "could", "make", "than", "been",
            "would", "who", "will", "my", "one", "about", "up", "out", "so", "them"
        ],
        "de": [
            "der", "die", "das", "und", "ist", "ich", "nicht", "mit", "ein", "eine",
            "auch", "auf", "sich", "als", "dem", "des", "zu", "es", "bei", "so",
            "war", "von", "aber", "noch", "wird", "sie", "nach", "an", "wie", "im",
            "fÃ¼r", "haben", "kann", "doch", "hier", "wenn", "dann", "wir", "man",
            "aus", "durch", "mehr", "oder", "hat", "ihm", "ihr", "uns", "ihn",
            "diese", "dieser", "dieses", "werden", "hatte", "sein", "sind", "mein"
        ],
        "ru": [
            "Ğ¸", "Ğ²", "Ğ½Ğµ", "Ğ½Ğ°", "Ñ‡Ñ‚Ğ¾", "Ğ¾Ğ½", "Ğ¾Ğ½Ğ°", "ÑÑ‚Ğ¾", "ĞºĞ°Ğº", "Ğ½Ğ¾",
            "ĞµĞ³Ğ¾", "ĞµÑ‘", "Ğ¾Ğ½Ğ¸", "Ğ¼Ñ‹", "Ğ²Ñ‹", "Ğ¶Ğµ", "Ğ¾Ñ‚", "Ğ·Ğ°", "Ğ¿Ğ¾", "Ğ¸Ğ·",
            "ÑƒĞ¶Ğµ", "Ñ‚Ğ°Ğº", "Ğ±Ñ‹Ğ»", "Ğ±Ñ‹Ğ»Ğ°", "Ğ±Ñ‹Ğ»Ğ¾", "Ğ±Ñ‹Ğ»Ğ¸", "ĞµÑÑ‚ÑŒ", "Ğ½ĞµÑ‚", "Ğ´Ğ°", "Ğ±Ñ‹",
            "ĞµÑĞ»Ğ¸", "Ñ‚Ğ¾", "Ğ²ÑĞµ", "Ğ¸Ğ»Ğ¸", "ĞºĞ¾Ğ³Ğ´Ğ°", "Ğ¸Ñ…", "Ñ‚Ğ°Ğ¼", "Ğ³Ğ´Ğµ", "ĞºÑ‚Ğ¾", "Ñ‡ĞµĞ¼",
            "Ğ½Ğ°Ñ", "Ğ²Ğ°Ñ", "Ğ¼Ğ½Ğµ", "Ñ‚ĞµĞ±Ğµ", "ÑĞµĞ±Ñ", "Ñ‚ÑƒÑ‚", "ĞµÑ‰Ñ‘", "Ğ¾Ñ‡ĞµĞ½ÑŒ", "Ğ¸Ğ¼", "ĞµĞ¹"
        ],
    }

    # â”€â”€ Score por stopwords â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    scores = {lang: 0 for lang in stopwords}
    for lang, words in stopwords.items():
        for w in words:
            if w in palavras_amostra:
                scores[lang] += 1

    # â”€â”€ Score por bigramas comuns â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    bigramas_amostra = set(
        " ".join(p) for p in zip(amostra.split(), amostra.split()[1:])
    )
    bigramas = {
        "pt": ["de que", "para o", "para a", "nÃ£o Ã©", "que nÃ£o", "Ã© que",
               "da que", "no que", "a gente", "vai ser"],
        "en": ["of the", "in the", "to the", "is a", "it is", "there is",
               "do not", "does not", "i am", "you are"],
        "de": ["in der", "in die", "auf der", "auf die", "ist ein", "ist die",
               "nicht die", "nicht der", "ich bin", "es gibt"],
        "ru": ["Ğ½Ğµ Ğ±Ñ‹Ğ»Ğ¾", "Ñ‡Ñ‚Ğ¾ ÑÑ‚Ğ¾", "Ğ¾Ğ½ Ğ±Ñ‹Ğ»", "Ğ¾Ğ½Ğ° Ğ±Ñ‹Ğ»Ğ°", "Ğ² Ñ‚Ğ¾Ğ¼", "Ğ¸Ğ· Ğ½Ğ¸Ñ…",
               "ÑÑ‚Ğ¾ Ğ±Ñ‹Ğ»", "ÑÑ‚Ğ¾ Ğ±Ñ‹Ğ»Ğ°", "ĞºĞ°Ğº ÑÑ‚Ğ¾", "Ğ½Ğ° ÑÑ‚Ğ¾"],
    }
    for lang, bigrams in bigramas.items():
        for bg in bigrams:
            if bg in bigramas_amostra:
                scores[lang] += 2  # bigramas valem mais que unigramas

    melhor = max(scores, key=scores.get)
    return melhor if scores[melhor] > 0 else "pt"


# â”€â”€ Header â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.title("Marina-Socioling")
st.caption("Rbrul â€” Johnson (2009) Â· Variationist â€” ACL 2024")
st.markdown("---")

# â”€â”€ Upload â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
uploaded_files = st.file_uploader(
    "Upload de arquivos CSV ou TXT",
    type=["csv", "txt"],
    accept_multiple_files=True,
    help="CSV ou TXT com cabeÃ§alho. Separador: vÃ­rgula (CSV) ou tabulaÃ§Ã£o (TXT).",
)

if not uploaded_files:
    st.info("FaÃ§a o upload de um ou mais arquivos CSV/TXT para comeÃ§ar.")
    st.stop()

dfs = []
for f in uploaded_files:
    _df = pd.read_csv(f, sep="\t" if f.name.endswith(".txt") else ",")
    _df["_arquivo"] = f.name
    dfs.append(_df)

df = pd.concat(dfs, ignore_index=True)
colunas = [c for c in df.columns if c != "_arquivo"]

with st.expander(f"PrÃ©-visualizaÃ§Ã£o â€” {len(df)} linhas Â· {len(colunas)} colunas Â· {len(uploaded_files)} arquivo(s)"):
    st.dataframe(df.head(20), use_container_width=True)

st.markdown("---")

# â”€â”€ DetecÃ§Ã£o automÃ¡tica â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
binÃ¡rias    = detectar_binÃ¡rias(df)
cols_texto  = detectar_textos(df)
falante     = detectar_falante(df)
excluir_base = set(cols_texto) | {falante or ""}
sociais     = detectar_sociais(df, excluir_base)
idioma      = detectar_idioma(df, cols_texto) if cols_texto else "pt"

tem_rbrul        = len(binÃ¡rias) > 0
tem_variationist = len(cols_texto) > 0 and len(sociais) > 0

with st.expander("ğŸ” DetecÃ§Ã£o automÃ¡tica", expanded=True):
    col1, col2 = st.columns(2)
    with col1:
        st.markdown("**Rbrul**")
        if tem_rbrul:
            st.success(f"âœ… VariÃ¡veis dependentes detectadas: {len(binÃ¡rias)}")
            for b in binÃ¡rias:
                st.info(f"`{b}` â€” valores: {df[b].unique().tolist()}")
            st.info(f"Efeito aleatÃ³rio: `{falante or 'nenhum'}`")
            excluir_fatores = set(binÃ¡rias) | {falante or ""}
            fatores_globais = [c for c in colunas if c not in excluir_fatores and c not in cols_texto]
            st.info(f"Fatores: `{', '.join(fatores_globais)}`")
        else:
            st.warning("Nenhuma coluna binÃ¡ria detectada.")
    with col2:
        st.markdown("**Variationist**")
        if tem_variationist:
            st.success(f"âœ… Colunas de texto: {cols_texto}")
            st.success(f"âœ… VariÃ¡veis sociais: {sociais}")
            st.info(f"Idioma detectado: `{idioma}`")
        else:
            st.warning("Nenhuma coluna de texto ou variÃ¡vel social detectada.")

st.markdown("---")

# â”€â”€ BotÃ£o Ãºnico â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if st.button("â–¶ Rodar anÃ¡lise completa", type="primary", use_container_width=True):

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # RBRUL â€” um modelo por variÃ¡vel dependente binÃ¡ria
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    if tem_rbrul:
        st.subheader("ğŸ“Š Rbrul â€” RegressÃ£o LogÃ­stica Variacionista")

        for dep_var in binÃ¡rias:
            st.markdown(f"#### Modelo: `{dep_var}`")
            fatores = [c for c in colunas
                       if c != dep_var
                       and c != falante
                       and c not in cols_texto]

            with st.spinner(f"Rodando modelo para `{dep_var}`..."):
                tmp_csv = os.path.join(DADOS_PATH, f"rbrul_{dep_var}.csv")
                df[colunas].to_csv(tmp_csv, index=False)

                cmd = ["Rscript", RBRUL_SCRIPT, tmp_csv, dep_var, ",".join(fatores)]
                if falante:
                    cmd.append(falante)

                result = subprocess.run(cmd, capture_output=True, text=True, timeout=120)

            if result.returncode == 0:
                st.success(f"âœ… Modelo `{dep_var}` concluÃ­do!")
                st.code(result.stdout, language="r")
                st.download_button(
                    f"â¬‡ï¸ Baixar output â€” {dep_var} (.txt)",
                    data=result.stdout,
                    file_name=f"rbrul_{dep_var}.txt",
                    mime="text/plain",
                    key=f"dl_rbrul_{dep_var}",
                )
            else:
                st.error(f"âŒ Erro no modelo `{dep_var}`.")
                st.code(result.stderr, language="bash")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # VARIATIONIST â€” uma anÃ¡lise por variÃ¡vel social, todas as mÃ©tricas
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    if tem_variationist:
        st.subheader("ğŸ“ˆ Variationist â€” MÃ©tricas de AssociaÃ§Ã£o")

        for col_texto in cols_texto:
            df = corrigir_texto(df, col_texto)

        for col_variavel in sociais:
            st.markdown(f"#### VariÃ¡vel social: `{col_variavel}`")

            with st.spinner(f"Calculando mÃ©tricas para `{col_variavel}`..."):
                try:
                    from variationist import Inspector, InspectorArgs, Visualizer, VisualizerArgs

                    col_texto_atual = cols_texto[0]
                    tmp_tsv = os.path.join(DADOS_PATH, f"variationist_{col_variavel}.tsv")
                    df[[col_texto_atual, col_variavel]].to_csv(tmp_tsv, sep="\t", index=False)

                    ins_args = InspectorArgs(
                        text_names=[col_texto_atual],
                        var_names=[col_variavel],
                        metrics=TODAS_METRICAS,
                        n_tokens=1,
                        language=idioma,
                        stopwords=true,
                        lowercase=True,
                    )

                    res = Inspector(dataset=tmp_tsv, args=ins_args).inspect()
                    st.success(f"âœ… AnÃ¡lise `{col_variavel}` concluÃ­da!")

                    tabs = st.tabs(TODAS_METRICAS)
                    for tab, metrica in zip(tabs, TODAS_METRICAS):
                        with tab:
                            try:
                                dados_metrica = res.get(metrica, {})
                                rows = []
                                for token, variantes in list(dados_metrica.items())[:20]:
                                    for variante, score in variantes.items():
                                        rows.append({"token": token, "variante": variante, "score": score})
                                if rows:
                                    df_tab = pd.DataFrame(rows).sort_values("score", ascending=False)
                                    st.dataframe(df_tab, use_container_width=True)
                                    fig = px.bar(df_tab.head(20), x="token", y="score",
                                                 color="variante", title=f"{metrica} Â· {col_variavel} â€” Top 20")
                                    st.plotly_chart(fig, use_container_width=True)
                                else:
                                    st.info("Sem dados para esta mÃ©trica.")
                            except Exception:
                                st.json(res.get(metrica, {}))

                    charts_path = os.path.join(DADOS_PATH, "charts")
                    os.makedirs(charts_path, exist_ok=True)
                    vis_args = VisualizerArgs(output_folder=charts_path, output_formats=["html"])
                    Visualizer(input_json=res, args=vis_args).create()

                    st.download_button(
                        f"â¬‡ï¸ Baixar resultados â€” {col_variavel} (.json)",
                        data=json.dumps(res, indent=2, ensure_ascii=False),
                        file_name=f"variationist_{col_variavel}.json",
                        mime="application/json",
                        key=f"dl_var_{col_variavel}",
                    )

                except Exception as e:
                    st.error(f"âŒ Erro em `{col_variavel}`: {e}")
                    st.exception(e)
