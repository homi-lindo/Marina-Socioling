import streamlit as st
import pandas as pd
import subprocess
import os
import json
import re
import io
import plotly.express as px

# â”€â”€ FunÃ§Ãµes GoldVarb â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def parse_goldvarb(conteudo_bytes: bytes) -> pd.DataFrame:
    linhas = conteudo_bytes.decode("latin-1").splitlines()
    rows = []
    for linha in linhas:
        linha = linha.strip()
        if not linha or not linha.startswith("("):
            continue
        linha = linha.lstrip("(")
        partes = re.split(r'\s+', linha, maxsplit=1)
        if len(partes) < 2:
            continue
        codigo, variante = partes[0], partes[1].strip()
        row = {f"grupo_{chr(65+i)}": c for i, c in enumerate(codigo)}
        row["variante"] = variante
        rows.append(row)
    return pd.DataFrame(rows)

def exportar_goldvarb(df: pd.DataFrame, col_variante: str = "variante") -> str:
    colunas_grupo = [c for c in df.columns if c != col_variante]
    linhas = []
    for _, row in df.iterrows():
        codigo = "".join(str(row[c]) for c in colunas_grupo)
        variante = row[col_variante]
        linhas.append(f"({codigo}   {variante}")
    return "\n".join(linhas)

# â”€â”€ ConfiguraÃ§Ã£o da pÃ¡gina â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

st.set_page_config(
    page_title="Marina-Socioling",
    layout="wide",
    initial_sidebar_state="collapsed",
)

DADOS_PATH = os.environ.get("DADOS_PATH", "/app/dados")
RBRUL_SCRIPT = "/app/scripts/run_rbrul.R"

METRICAS_PMI = ["pmi", "n_pmi", "p_pmi", "np_pmi", "w_pmi", "nw_pmi",
                "pw_pmi", "npw_pmi", "np_relevance", "nw_relevance", "npw_relevance"]
METRICAS_LEXICAIS = ["ttr", "root_ttr", "maas", "log_ttr"]
METRICAS_CORPUS = ["freq", "stats"]
TODAS_METRICAS = METRICAS_PMI + METRICAS_LEXICAIS + METRICAS_CORPUS

CANDIDATOS_SOCIAIS = [
    "genero", "gÃªnero", "faixa_etaria", "faixa etÃ¡ria", "escolaridade",
    "regiao", "regiÃ£o", "estilo", "classe", "sexo", "grupo"
]

CANDIDATOS_RAND = [
    "falante", "speaker", "informante", "participante", "sujeito",
    "palavra", "item", "item_lexical", "lexema", "vocÃ¡bulo",
    "entrevista", "sessao", "sessÃ£o", "gravacao", "gravaÃ§Ã£o",
    "comunidade", "cidade", "bairro", "localidade"
]

# â”€â”€ Helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def detectar_binÃ¡rias(df):
    """
    Retorna colunas com 2â€“6 valores Ãºnicos do tipo object.
    Prioriza dep_goldvarb se existir (arquivo GoldVarb).
    """
    if "dep_goldvarb" in df.columns:
        return ["dep_goldvarb"]
    return [c for c in df.columns
            if df[c].dtype == object and 2 <= df[c].nunique() <= 6]

def detectar_dependente(df):
    """
    Retorna (coluna, tipo) onde tipo Ã© 'binaria' ou 'multinivel'.
    Prioriza dep_goldvarb, depois colunas com 2-6 valores Ãºnicos.
    """
    if "dep_goldvarb" in df.columns:
        n = df["dep_goldvarb"].nunique()
        return [("dep_goldvarb", "binaria" if n == 2 else "multinivel")]
        candidatas = []
    for c in df.columns:
        n = df[c].nunique()
        if 2 <= n <= 6 and df[c].dtype == object:
            tipo = "binaria" if n == 2 else "multinivel"
            candidatas.append((c, tipo))
    return candidatas

def gerar_pares(df, col):
    """Para variÃ¡vel multinÃ­vel, gera subsets binÃ¡rios par a par."""
    from itertools import combinations
    valores = df[col].dropna().unique().tolist()
    pares = []
    for v1, v2 in combinations(valores, 2):
        subset = df[df[col].isin([v1, v2])].copy()
        pares.append((f"{v1}_vs_{v2}", subset, col))
    return pares

def detectar_textos(df):
    cols = []
    for col in df.columns:
        if df[col].dtype == object:
            media = df[col].dropna().str.split().str.len().mean()
            if media and media > 3:
                cols.append(col)
    return cols

def detectar_efeitos_aleatorios(df):
    return [col for col in df.columns if col.lower() in CANDIDATOS_RAND]

def detectar_sociais(df, excluir):
    """Retorna todas as colunas que parecem variÃ¡veis sociais â€” incluindo binÃ¡rias."""
    sociais = []
    for col in df.columns:
        if col in excluir:
            continue
        if col.lower() in CANDIDATOS_SOCIAIS:
            sociais.append(col)
    if not sociais:
        for col in df.columns:
            if col not in excluir and df[col].dtype == object and 2 <= df[col].nunique() <= 10:
                sociais.append(col)
    return sociais

def corrigir_texto(df, col):
    df[col] = df[col].astype(str).apply(
        lambda x: re.sub(r'([a-zÃ¡Ã Ã£Ã¢Ã©ÃªÃ­Ã³Ã´ÃµÃºÃ¼Ã§A-Z])([A-ZÃÃ€ÃƒÃ‚Ã‰ÃŠÃÃ“Ã”Ã•ÃšÃœÃ‡])', r'\1 \2', x)
    )
    return df

def detectar_idioma(df, cols_texto):
    amostra = ""
    for col in cols_texto:
        amostra += " " + " ".join(df[col].dropna().head(50).tolist()).lower()
    amostra_padded = f" {amostra} "

    if sum(1 for c in amostra if '\u0400' <= c <= '\u04FF') > 10:
        return "ru"
    if sum(1 for c in amostra if c in "Ã¤Ã¶Ã¼ÃŸÃ„Ã–Ãœ") > 10:
        return "de"

    stopwords = {
        "pt": [
            "que", "nÃ£o", "uma", "com", "para", "mais", "por", "ele", "ela", "mas",
            "como", "seu", "sua", "dos", "das", "nos", "nas", "isso", "esse", "essa",
            "este", "esta", "aqui", "entÃ£o", "tambÃ©m", "jÃ¡", "muito", "bem", "quando",
            "onde", "quem", "qual", "porque", "assim", "ainda", "depois", "antes",
            "sempre", "nunca", "havia", "seria", "estava", "foram", "tinha", "tudo",
            "nada", "cada", "outro", "outra", "gente", "hoje", "agora", "aquele",
            "aquela", "nosso", "nossa", "vocÃªs", "eles", "elas", "sobre", "entre", "atÃ©"
        ],
        "en": [
            "the", "and", "is", "of", "to", "in", "that", "it", "was", "for",
            "on", "are", "with", "his", "they", "at", "be", "this", "from", "or",
            "had", "by", "not", "but", "what", "all", "were", "when", "we", "there",
            "can", "an", "your", "which", "their", "said", "do", "into", "has",
            "more", "her", "him", "time", "could", "make", "than", "been", "would",
            "who", "will", "my", "one", "about", "up", "out", "so", "them"
        ],
        "de": [
            "und", "ist", "ich", "nicht", "mit", "ein", "eine", "auch", "auf",
            "sich", "als", "dem", "des", "zu", "bei", "war", "von", "aber", "noch",
            "wird", "sie", "nach", "wie", "fÃ¼r", "haben", "kann", "doch", "hier",
            "wenn", "dann", "wir", "man", "aus", "durch", "mehr", "oder", "hat",
            "ihm", "ihr", "uns", "ihn", "diese", "dieser", "dieses", "werden", "sein"
        ],
        "ru": [
            "Ğ¸", "Ğ²", "Ğ½Ğµ", "Ğ½Ğ°", "Ñ‡Ñ‚Ğ¾", "Ğ¾Ğ½", "Ğ¾Ğ½Ğ°", "ÑÑ‚Ğ¾", "ĞºĞ°Ğº", "Ğ½Ğ¾",
            "ĞµĞ³Ğ¾", "ĞµÑ‘", "Ğ¾Ğ½Ğ¸", "Ğ¼Ñ‹", "Ğ²Ñ‹", "Ğ¶Ğµ", "Ğ¾Ñ‚", "Ğ·Ğ°", "Ğ¿Ğ¾", "Ğ¸Ğ·",
            "ÑƒĞ¶Ğµ", "Ñ‚Ğ°Ğº", "Ğ±Ñ‹Ğ»", "Ğ±Ñ‹Ğ»Ğ°", "Ğ±Ñ‹Ğ»Ğ¾", "Ğ±Ñ‹Ğ»Ğ¸", "ĞµÑÑ‚ÑŒ", "Ğ½ĞµÑ‚", "Ğ´Ğ°", "Ğ±Ñ‹",
            "ĞµÑĞ»Ğ¸", "Ñ‚Ğ¾", "Ğ²ÑĞµ", "Ğ¸Ğ»Ğ¸", "ĞºĞ¾Ğ³Ğ´Ğ°", "Ğ¸Ñ…", "Ñ‚Ğ°Ğ¼", "Ğ³Ğ´Ğµ", "ĞºÑ‚Ğ¾", "Ñ‡ĞµĞ¼"
        ],
    }

    bigramas = {
        "pt": ["de que", "para o", "para a", "nÃ£o Ã©", "que nÃ£o", "Ã© que",
               "a gente", "vai ser", "que eu", "eu nÃ£o", "eu tÃ´", "tÃ¡ tudo"],
        "en": ["of the", "in the", "to the", "is a", "it is", "there is",
               "do not", "i am", "you are", "he was", "she was"],
        "de": ["in der", "auf der", "ist ein", "ist die", "nicht die",
               "ich bin", "es gibt", "haben wir", "das ist", "ich habe"],
        "ru": ["Ğ½Ğµ Ğ±Ñ‹Ğ»Ğ¾", "Ñ‡Ñ‚Ğ¾ ÑÑ‚Ğ¾", "Ğ¾Ğ½ Ğ±Ñ‹Ğ»", "Ğ¾Ğ½Ğ° Ğ±Ñ‹Ğ»Ğ°", "Ğ² Ñ‚Ğ¾Ğ¼",
               "ÑÑ‚Ğ¾ Ğ±Ñ‹Ğ»", "ĞºĞ°Ğº ÑÑ‚Ğ¾", "Ğ½Ğ° ÑÑ‚Ğ¾", "Ğ¸Ğ· Ğ½Ğ¸Ñ…"],
    }

    scores = {lang: 0 for lang in stopwords}
    for lang, words in stopwords.items():
        for w in words:
            if f" {w} " in amostra_padded:
                scores[lang] += 1
    for lang, bigrams in bigramas.items():
        for bg in bigrams:
            if f" {bg} " in amostra_padded:
                scores[lang] += 2

    melhor = max(scores, key=scores.get)
    return melhor if scores[melhor] > 0 else "pt"

# â”€â”€ Header â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

st.title("Marina-Socioling")
st.caption("Rbrul â€” Johnson (2009) Â· Variationist â€” ACL 2024")
st.markdown("---")

# â”€â”€ Upload â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

uploaded_files = st.file_uploader(
    "Upload de arquivos CSV, TXT ou GoldVarb (.tok/.cod)",
    type=["csv", "txt", "tok", "cod"],
    accept_multiple_files=True,
    help="CSV/TXT com cabeÃ§alho, ou arquivo GoldVarb no formato (XXXXXXX   variante",
)

if not uploaded_files:
    st.info("FaÃ§a o upload de um ou mais arquivos para comeÃ§ar.")
    st.stop()

dfs = []
for f in uploaded_files:
    conteudo = f.read()
    ext = f.name.rsplit(".", 1)[-1].lower()
    if ext in ("tok", "cod"):
        _df = parse_goldvarb(conteudo)
        _df = _df.rename(columns={"grupo_A": "dep_var_goldvarb"})
        st.info(f"ğŸ“‚ GoldVarb detectado: `{f.name}` â†’ `dep_var_goldvarb` = variÃ¡vel dependente")
    elif ext == "txt":
        amostra = conteudo.decode("latin-1", errors="replace").lstrip()
        if amostra.startswith("("):
            _df = parse_goldvarb(conteudo)
            _df = _df.rename(columns={"grupo_A": "dep_var_goldvarb"})
            st.info(f"ğŸ“‚ Formato GoldVarb detectado em `{f.name}`")
        else:
            _df = pd.read_csv(io.BytesIO(conteudo), sep="\t")
    else:
        _df = pd.read_csv(io.BytesIO(conteudo))
    _df["_arquivo"] = f.name
    dfs.append(_df)

df = pd.concat(dfs, ignore_index=True)
colunas = [c for c in df.columns if c != "_arquivo"]

with st.expander(f"PrÃ©-visualizaÃ§Ã£o â€” {len(df)} linhas Â· {len(colunas)} colunas Â· {len(uploaded_files)} arquivo(s)"):
    st.dataframe(df.head(20), use_container_width=True)

st.markdown("---")

# â”€â”€ DetecÃ§Ã£o automÃ¡tica â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

binÃ¡rias = detectar_binÃ¡rias(df)

def detectar_binÃ¡rias(df):
    if "dep_var_goldvarb" in df.columns:
        return ["dep_var_goldvarb"]
    return [c for c in df.columns
            if df[c].dtype == object and 2 <= df[c].nunique() <= 6]
    
cols_texto = detectar_textos(df)
rand_detectados = detectar_efeitos_aleatorios(df)
excluir_sociais = set(cols_texto)
sociais = detectar_sociais(df, excluir_sociais)
idioma = detectar_idioma(df, cols_texto) if cols_texto else "pt"

tem_rbrul = len(binÃ¡rias) > 0
tem_variationist = len(cols_texto) > 0 and len(sociais) > 0

with st.expander("DetecÃ§Ã£o automÃ¡tica", expanded=True):
    col1, col2 = st.columns(2)
    with col1:
        st.markdown("**Rbrul**")
        if tem_rbrul:
            st.success(f"VariÃ¡veis dependentes: {len(binÃ¡rias)}")
            for b in binÃ¡rias:
                st.info(f"`{b}` â€” valores: {df[b].unique().tolist()}")
            st.markdown("**Efeitos aleatÃ³rios**")
            rand_selecionados = []
            if rand_detectados:
                for col in rand_detectados:
                    if st.checkbox(f"`{col}`", value=True, key=f"rand_{col}"):
                        rand_selecionados.append(col)
            else:
                st.info("Nenhum efeito aleatÃ³rio detectado.")
            excluir_fatores = set(binÃ¡rias) | set(rand_detectados) | set(cols_texto)
            fatores_globais = [c for c in colunas if c not in excluir_fatores]
            st.info(f"Fatores: `{', '.join(fatores_globais)}`")
        else:
            st.warning("Nenhuma coluna binÃ¡ria detectada.")
    with col2:
        st.markdown("**Variationist**")
        if tem_variationist:
            st.success(f"Colunas de texto: {cols_texto}")
            st.success(f"VariÃ¡veis sociais: {sociais}")
            st.info(f"Idioma detectado: `{idioma}`")
        else:
            st.warning("Nenhuma coluna de texto ou variÃ¡vel social detectada.")

st.markdown("---")

# â”€â”€ BotÃ£o Ãºnico â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

if st.button("â–¶ Rodar anÃ¡lise completa", type="primary", use_container_width=True):

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # RBRUL â€” um modelo por variÃ¡vel dependente binÃ¡ria
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    if tem_rbrul:
        st.subheader("Rbrul â€” RegressÃ£o LogÃ­stica Variacionista")
        for dep_var in binÃ¡rias:
            st.markdown(f"#### Modelo: `{dep_var}`")
            fatores = [c for c in colunas
                       if c != dep_var
                       and c not in rand_detectados
                       and c not in cols_texto]
            with st.spinner(f"Rodando modelo para `{dep_var}`..."):
                tmp_csv = os.path.join(DADOS_PATH, f"rbrul_{dep_var}.csv")
                df[colunas].to_csv(tmp_csv, index=False)
                rand_arg = ",".join(rand_selecionados) if rand_selecionados else ""
                cmd = ["Rscript", RBRUL_SCRIPT, tmp_csv, dep_var, ",".join(fatores)]
                if rand_arg:
                    cmd.append(rand_arg)
                result = subprocess.run(cmd, capture_output=True, text=True, timeout=120)

            if result.returncode == 0:
                st.success(f"Modelo `{dep_var}` concluÃ­do!")
                st.code(result.stdout, language="r")
                st.download_button(
                    f"â¬‡ï¸ Baixar output â€” {dep_var} (.txt)",
                    data=result.stdout,
                    file_name=f"rbrul_{dep_var}.txt",
                    mime="text/plain",
                    key=f"dl_rbrul_{dep_var}",
                )
                goldvarb_out = exportar_goldvarb(df)
                st.download_button(
                    f"â¬‡ï¸ Baixar como GoldVarb â€” {dep_var} (.tok)",
                    data=goldvarb_out.encode("latin-1"),
                    file_name=f"corpus_{dep_var}.tok",
                    mime="text/plain",
                    key=f"dl_tok_{dep_var}",
                )
            else:
                st.error(f"âŒ Erro no modelo `{dep_var}`.")
                st.code(result.stderr, language="bash")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # VARIATIONIST â€” uma anÃ¡lise por variÃ¡vel social, todas as mÃ©tricas
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    if tem_variationist:
        st.subheader("Variationist â€” MÃ©tricas de AssociaÃ§Ã£o")
        for col_texto in cols_texto:
            df = corrigir_texto(df, col_texto)
        for col_variavel in sociais:
            st.markdown(f"#### VariÃ¡vel social: `{col_variavel}`")
            with st.spinner(f"Calculando mÃ©tricas para `{col_variavel}`..."):
                try:
                    from variationist import Inspector, InspectorArgs, Visualizer, VisualizerArgs

                    col_texto_atual = cols_texto[0]
                    tmp_tsv = os.path.join(DADOS_PATH, f"variationist_{col_variavel}.tsv")
                    df[[col_texto_atual, col_variavel]].to_csv(tmp_tsv, sep="\t", index=False)

                    ins_args = InspectorArgs(
                        text_names=[col_texto_atual],
                        var_names=[col_variavel],
                        metrics=TODAS_METRICAS,
                        n_tokens=1,
                        language=idioma,
                        stopwords=True,
                        lowercase=True,
                    )

                    res = Inspector(dataset=tmp_tsv, args=ins_args).inspect()
                    st.success(f"AnÃ¡lise `{col_variavel}` concluÃ­da!")

                    tabs = st.tabs(TODAS_METRICAS)
                    for tab, metrica in zip(tabs, TODAS_METRICAS):
                        with tab:
                            try:
                                dados_metrica = res.get(metrica, {})
                                rows = []
                                for token, variantes in list(dados_metrica.items())[:20]:
                                    for variante, score in variantes.items():
                                        rows.append({"token": token, "variante": variante, "score": score})
                                if rows:
                                    df_tab = pd.DataFrame(rows).sort_values("score", ascending=False)
                                    st.dataframe(df_tab, use_container_width=True)
                                    fig = px.bar(df_tab.head(20), x="token", y="score",
                                                 color="variante",
                                                 title=f"{metrica} Â· {col_variavel} â€” Top 20")
                                    st.plotly_chart(fig, use_container_width=True)
                                else:
                                    st.info("Sem dados para esta mÃ©trica.")
                            except Exception:
                                st.json(res.get(metrica, {}))

                    charts_path = os.path.join(DADOS_PATH, "charts")
                    os.makedirs(charts_path, exist_ok=True)
                    vis_args = VisualizerArgs(output_folder=charts_path, output_formats=["html"])
                    Visualizer(input_json=res, args=vis_args).create()

                    st.download_button(
                        f"â¬‡ï¸ Baixar resultados â€” {col_variavel} (.json)",
                        data=json.dumps(res, indent=2, ensure_ascii=False),
                        file_name=f"variationist_{col_variavel}.json",
                        mime="application/json",
                        key=f"dl_var_{col_variavel}",
                    )

                except Exception as e:
                    st.error(f"âŒ Erro em `{col_variavel}`: {e}")
                    st.exception(e)
